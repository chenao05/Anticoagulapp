from langchain_ollama import OllamaLLM

llm = OllamaLLM(model="llama3")
respuesta = llm.invoke("Â¿CuÃ¡l es la dosis inicial de warfarina en fibrilaciÃ³n auricular?")
print("ðŸ§  Respuesta de Ollama:")
print(respuesta)